{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from utils import create_win_data, normalize, denormalize, features_and_labels, train_test_split, evaluate\n",
    "from models import BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Neu</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>2683.729980</td>\n",
       "      <td>2695.889893</td>\n",
       "      <td>2682.360107</td>\n",
       "      <td>2695.810059</td>\n",
       "      <td>2695.810059</td>\n",
       "      <td>3.397430e+09</td>\n",
       "      <td>0.12025</td>\n",
       "      <td>0.74875</td>\n",
       "      <td>0.13100</td>\n",
       "      <td>-0.042250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>2697.850098</td>\n",
       "      <td>2714.370117</td>\n",
       "      <td>2697.770020</td>\n",
       "      <td>2713.060059</td>\n",
       "      <td>2713.060059</td>\n",
       "      <td>3.544030e+09</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>2719.310059</td>\n",
       "      <td>2729.290039</td>\n",
       "      <td>2719.070068</td>\n",
       "      <td>2723.989990</td>\n",
       "      <td>2723.989990</td>\n",
       "      <td>3.697340e+09</td>\n",
       "      <td>0.04325</td>\n",
       "      <td>0.78400</td>\n",
       "      <td>0.17275</td>\n",
       "      <td>0.431975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>2731.330078</td>\n",
       "      <td>2743.449951</td>\n",
       "      <td>2727.919922</td>\n",
       "      <td>2743.149902</td>\n",
       "      <td>2743.149902</td>\n",
       "      <td>3.239280e+09</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.85100</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.541300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>2742.669922</td>\n",
       "      <td>2748.510010</td>\n",
       "      <td>2737.600098</td>\n",
       "      <td>2747.709961</td>\n",
       "      <td>2747.709961</td>\n",
       "      <td>3.246160e+09</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.94350</td>\n",
       "      <td>0.05650</td>\n",
       "      <td>0.318450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2018-01-02  2683.729980  2695.889893  2682.360107  2695.810059  2695.810059   \n",
       "2018-01-03  2697.850098  2714.370117  2697.770020  2713.060059  2713.060059   \n",
       "2018-01-04  2719.310059  2729.290039  2719.070068  2723.989990  2723.989990   \n",
       "2018-01-05  2731.330078  2743.449951  2727.919922  2743.149902  2743.149902   \n",
       "2018-01-08  2742.669922  2748.510010  2737.600098  2747.709961  2747.709961   \n",
       "\n",
       "                  Volume      Neg      Neu      Pos  Compound  \n",
       "Date                                                           \n",
       "2018-01-02  3.397430e+09  0.12025  0.74875  0.13100 -0.042250  \n",
       "2018-01-03  3.544030e+09  0.00000  0.00000  0.00000  0.000000  \n",
       "2018-01-04  3.697340e+09  0.04325  0.78400  0.17275  0.431975  \n",
       "2018-01-05  3.239280e+09  0.00000  0.85100  0.14900  0.541300  \n",
       "2018-01-08  3.246160e+09  0.00000  0.94350  0.05650  0.318450  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv( \"data/result/sp500-with-forbes-sentiment.csv\", index_col=\"Date\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (1559, 7)\n"
     ]
    }
   ],
   "source": [
    "data = df[ [ \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Compound\", \"Adj Close\"]].values\n",
    "\n",
    "print( f\"Data Shape: { data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 0.85\n",
    "SEQUENCE_LENGTH = 11\n",
    "INPUT_DIM = data.shape[ -1]\n",
    "INPUT_TIMESTEPS = 10\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TEST_BATCH_SIZE = 1\n",
    "NEURONS = 50\n",
    "STATEFUL = False\n",
    "UNROLL = True\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (1325, 7)\n",
      "Test Data Shape: (234, 7)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split( data, TRAIN_SPLIT)\n",
    "\n",
    "print( f\"Train Data Shape: { train_data.shape}\")\n",
    "print( f\"Test Data Shape: { test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Window Data shape: (1314, 11, 7)\n"
     ]
    }
   ],
   "source": [
    "train_data_windows = create_win_data( train_data, SEQUENCE_LENGTH)\n",
    "\n",
    "if STATEFUL:\n",
    "\texcess_windows = len( train_data_windows) % TRAIN_BATCH_SIZE\n",
    "\ttrain_data_windows = train_data_windows[ :len( train_data_windows) - excess_windows]\n",
    "\n",
    "X_train, y_train = features_and_labels( train_data_windows)\n",
    "\n",
    "normalized_train_data, record_min_train, record_max_train = normalize( train_data_windows)\n",
    "\n",
    "X_train_normalized, y_train_normalized = features_and_labels( normalized_train_data)\n",
    "\n",
    "print( f\"Train Window Data shape: { train_data_windows.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Window Data shape: (223, 11, 7)\n"
     ]
    }
   ],
   "source": [
    "test_data_windows = create_win_data( test_data, SEQUENCE_LENGTH)\n",
    "\n",
    "if STATEFUL:\n",
    "\texcess_windows = len( test_data_windows) % TEST_BATCH_SIZE\n",
    "\ttest_data_windows = test_data_windows[ :len( test_data_windows) - excess_windows]\n",
    "\n",
    "X_test, y_test = features_and_labels( test_data_windows)\n",
    "\n",
    "normalized_test_data, record_min_test, record_max_test = normalize( test_data_windows)\n",
    "\n",
    "X_test_normalized, y_test_normalized = features_and_labels( normalized_test_data)\n",
    "\n",
    "print( f\"Test Window Data shape: { test_data_windows.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bidirectional Long Short-term Memory (Bi-LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirection  (None, 10, 100)           23200     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 100)               60400     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83701 (326.96 KB)\n",
      "Trainable params: 83701 (326.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bi_lstm = BiLSTM(\n",
    "\tNEURONS,\n",
    "\tbatch_size=TRAIN_BATCH_SIZE,\n",
    "\twindow_size=INPUT_TIMESTEPS,\n",
    "\tinput_dim=INPUT_DIM,\n",
    "\tstateful=STATEFUL,\n",
    "\tunroll=UNROLL\n",
    ")\n",
    "\n",
    "bi_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm.fit(\n",
    "\tinput=X_train_normalized,\n",
    "\ttarget=y_train_normalized,\n",
    "\tepochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate model prediction on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1155.48\n",
      "RMSE: 33.99\n",
      "MAE: 24.41\n",
      "MAPE: 0.71%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_normalized = bi_lstm.predict(\n",
    "\tinput=X_train_normalized,\n",
    "\tbatch_size=TRAIN_BATCH_SIZE\n",
    ")\n",
    "\n",
    "y_train_pred = denormalize( y_train_pred_normalized, record_min_train, record_max_train)\n",
    "\n",
    "mse, rmse, mae, mape = evaluate( y_train, y_train_pred)\n",
    "print( f\"MSE: { mse:.2f}\\nRMSE: { rmse:.2f}\\nMAE: { mae:.2f}\\nMAPE: { mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate model prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 765.34\n",
      "RMSE: 27.66\n",
      "MAE: 22.63\n",
      "MAPE: 0.50%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_normalized = bi_lstm.predict(\n",
    "\tinput=X_test_normalized,\n",
    "\tbatch_size=TEST_BATCH_SIZE\n",
    ")\n",
    "y_test_pred = denormalize( y_test_pred_normalized, record_min_test, record_max_test)\n",
    "\n",
    "mse, rmse, mae, mape = evaluate( y_test, y_test_pred)\n",
    "print( f\"MSE: { mse:.2f}\\nRMSE: { rmse:.2f}\\nMAE: { mae:.2f}\\nMAPE: { mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIES = 10\n",
    "\n",
    "train_mse_list = []\n",
    "train_rmse_list = []\n",
    "train_mae_list = []\n",
    "train_mape_list = []\n",
    "\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_mape_list = []\n",
    "\n",
    "for _ in range( TRIES):\n",
    "\tbi_lstm = BiLSTM(\n",
    "\t\tneurons=NEURONS,\n",
    "\t\tbatch_size=TRAIN_BATCH_SIZE,\n",
    "\t\twindow_size=INPUT_TIMESTEPS,\n",
    "\t\tinput_dim=INPUT_DIM,\n",
    "\t\tstateful=STATEFUL,\n",
    "\t\tunroll=UNROLL\n",
    "\t)\n",
    "\n",
    "\tbi_lstm.fit(\n",
    "\t\tinput=X_train_normalized,\n",
    "\t\ttarget=y_train_normalized,\n",
    "\t\tepochs=EPOCHS\n",
    "\t)\n",
    "\n",
    "\ty_train_pred_normalized = bi_lstm.predict( input=X_train_normalized, batch_size=TRAIN_BATCH_SIZE)\n",
    "\ty_train_pred = denormalize( y_train_pred_normalized, record_min_train, record_max_train)\n",
    "\n",
    "\ttrain_mse, train_rmse, train_mae, train_mape = evaluate( y_train, y_train_pred)\n",
    "\n",
    "\ttrain_mse_list.append( train_mse)\n",
    "\ttrain_rmse_list.append( train_rmse)\n",
    "\ttrain_mae_list.append( train_mae)\n",
    "\ttrain_mape_list.append( train_mape)\n",
    "\n",
    "\ty_test_pred_normalized = bi_lstm.predict( input=X_test_normalized, batch_size=TEST_BATCH_SIZE)\n",
    "\ty_test_pred = denormalize( y_test_pred_normalized, record_min_test, record_max_test)\n",
    "\n",
    "\ttest_mse, test_rmse, test_mae, test_mape = evaluate( y_test, y_test_pred)\n",
    "\n",
    "\ttest_mse_list.append( test_mse)\n",
    "\ttest_rmse_list.append( test_rmse)\n",
    "\ttest_mae_list.append( test_mae)\n",
    "\ttest_mape_list.append( test_mape)\n",
    "\n",
    "now = datetime.strftime( datetime.now(), \"%Y-%m-%dT%H-%M-%S\")\n",
    "\n",
    "pd.DataFrame( {\n",
    "\t\"train_mse\": train_mse_list,\n",
    "\t\"train_rmse\": train_rmse_list,\n",
    "\t\"train_mae\": train_mae_list,\n",
    "\t\"train_mape\": train_mape_list,\n",
    "\t\"test_mse\": test_mse_list,\n",
    "\t\"test_rmse\": test_rmse_list,\n",
    "\t\"test_mae\": test_mae_list,\n",
    "\t\"test_mape\": test_mape_list\n",
    "}).to_csv( f\"evaluations/sp500_BiLSTM_with_forbes_sentiment_{ now}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
